{"ast":null,"code":"var _jsxFileName = \"D:\\\\OpenAIVoice\\\\openvoice\\\\src\\\\App.js\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect } from 'react';\nimport axios from 'axios';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction App() {\n  _s();\n  const [messages, setMessages] = useState([]); // State to store the list of Q&A pairs\n  const [loading, setLoading] = useState(false); // Loading state for API call\n  const {\n    transcript,\n    listening,\n    resetTranscript\n  } = useSpeechRecognition(); // Speech recognition hooks\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    return /*#__PURE__*/_jsxDEV(\"div\", {\n      children: \"Your browser does not support speech recognition. Please use a modern browser.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 11,\n      columnNumber: 12\n    }, this);\n  }\n\n  // Function to start listening to speech\n  const handleStartListening = () => {\n    if (!listening) {\n      SpeechRecognition.startListening({\n        continuous: true\n      }); // Start continuous listening\n    }\n  };\n\n  // Function to stop listening to speech\n  const handleStopListening = () => {\n    if (listening) {\n      SpeechRecognition.stopListening(); // Stop listening when the button is clicked\n    }\n  };\n\n  // useEffect to call the API when listening stops\n  useEffect(() => {\n    if (!listening && transcript.trim()) {\n      const fetchResponse = async () => {\n        setLoading(true); // Start loading\n\n        try {\n          const response = await axios.post('http://localhost:4000/api/v1/search/QueryAnything',\n          // API endpoint\n          {\n            input: transcript // Send the transcribed message as input\n          }, {\n            headers: {\n              'Content-Type': 'application/json' // Set headers\n            }\n          });\n\n          // Extract the response message from the API\n          const aiMessage = response.data.message;\n\n          // Update messages state with the new Q&A\n          setMessages(prevMessages => [...prevMessages, {\n            question: transcript,\n            // Save the transcript as the question\n            answer: aiMessage // Save the AI response as the answer\n          }]);\n        } catch (error) {\n          console.error('Error fetching response from API:', error); // Handle error\n          setMessages(prevMessages => [...prevMessages, {\n            question: transcript,\n            // Save the transcript even on error\n            answer: 'Error fetching response. Please try again.' // Display error message\n          }]);\n        }\n        setLoading(false); // End loading\n      };\n      fetchResponse();\n    }\n  }, [listening, transcript]); // Dependency array to watch for changes in 'listening' and 'transcript'\n\n  // Function to reset the response text area\n  const handleResetResponses = () => {\n    setMessages([]); // Clear all Q&A pairs\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    style: {\n      padding: '20px',\n      maxWidth: '600px',\n      margin: 'auto'\n    },\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \"Chat AI : Your Personal Voice Assistance\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 83,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        marginBottom: '20px'\n      },\n      children: [/*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: handleStartListening,\n        style: {\n          padding: '10px',\n          fontSize: '16px',\n          marginRight: '10px'\n        },\n        disabled: listening // Disable if already listening\n        ,\n        children: \"Start Listening\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 85,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: handleStopListening,\n        style: {\n          padding: '10px',\n          fontSize: '16px',\n          marginRight: '10px'\n        },\n        disabled: !listening // Disable if not listening\n        ,\n        children: \"Stop Listening\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 92,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: handleResetResponses,\n        style: {\n          padding: '10px',\n          fontSize: '16px'\n        },\n        children: \"Reset Responses\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 99,\n        columnNumber: 9\n      }, this), listening && /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"Listening... Please speak now.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 105,\n        columnNumber: 23\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 84,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        marginBottom: '20px'\n      },\n      children: /*#__PURE__*/_jsxDEV(\"textarea\", {\n        value: transcript,\n        rows: \"4\",\n        cols: \"50\",\n        readOnly: true,\n        placeholder: \"Your transcribed text will appear here...\",\n        style: {\n          width: '100%',\n          marginBottom: '10px'\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 108,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 107,\n      columnNumber: 7\n    }, this), loading ? /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Loading response...\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 117,\n      columnNumber: 18\n    }, this) : /*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        marginTop: '20px'\n      },\n      children: /*#__PURE__*/_jsxDEV(\"textarea\", {\n        value: messages.map((msg, index) => `Question ${index + 1}:\\n${msg.question}\\nAnswer:\\n${msg.answer}\\n\\n`).join(''),\n        rows: \"10\",\n        cols: \"50\",\n        readOnly: true,\n        placeholder: \"AI responses will appear here...\",\n        style: {\n          width: '100%',\n          height: '200px'\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 119,\n        columnNumber: 11\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 118,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 82,\n    columnNumber: 5\n  }, this);\n}\n_s(App, \"/9Av/iUzsgfFbiFabnwfQAMjOuc=\", false, function () {\n  return [useSpeechRecognition];\n});\n_c = App;\nexport default App;\n\n// import React, { useState } from 'react';\n// import axios from 'axios';\n// import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\n// function App() {\n//   const [messages, setMessages] = useState(''); // State to store the API response\n//   const [loading, setLoading] = useState(false); // Loading state for API call\n//   const { transcript, listening, resetTranscript } = useSpeechRecognition(); // Speech recognition hooks\n\n//   if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n//     return <div>Your browser does not support speech recognition. Please use a modern browser.</div>;\n//   }\n\n//   // Handle microphone click event\n//   const handleMicClick = () => {\n//     if (listening) {\n//       SpeechRecognition.stopListening(); // Stop listening when button is clicked again\n//       handleSendMessage(transcript); // Send the message to OpenAI API\n//       resetTranscript(); // Reset transcript after sending\n//     } else {\n//       SpeechRecognition.startListening(); // Start listening when button is clicked\n//     }\n//   };\n\n//   // Function to send the transcribed message to the API\n//   const handleSendMessage = async (message) => {\n//     if (!message.trim()) {\n//       alert(\"Please say something before sending.\"); // Alert if the message is empty\n//       return;\n//     }\n\n//     setLoading(true); // Start loading\n\n//     try {\n//       const response = await axios.post(\n//         'http://localhost:4000/api/v1/search/QueryAnything', // API endpoint\n//         {\n//           input: message, // Send the transcribed message as input\n//         },\n//         {\n//           headers: {\n//             'Content-Type': 'application/json', // Set headers\n//           },\n//         }\n//       );\n\n//       // Extract the response message from the API\n//       const aiMessage = response.data.message;\n//       setMessages(aiMessage); // Update messages state with API response\n//     } catch (error) {\n//       console.error('Error fetching response from API:', error); // Handle error\n//       setMessages('Error fetching response. Please try again.'); // Display error message\n//     }\n\n//     setLoading(false); // End loading\n//   };\n\n//   return (\n//     <div style={{ padding: '20px', maxWidth: '600px', margin: 'auto' }}>\n//       <h1>Chat with AI using Voice</h1>\n//       <div style={{ marginBottom: '20px' }}>\n//         <button onClick={handleMicClick} style={{ padding: '10px', fontSize: '16px' }}>\n//           {listening ? 'Stop Listening' : 'Start Listening'}\n//         </button>\n//         {listening && <p>Listening... Please speak now.</p>}\n//       </div>\n//       {loading && <p>Loading response...</p>}\n//       <div style={{ marginTop: '20px' }}>\n//         <textarea\n//           value={transcript}\n//           rows=\"4\"\n//           cols=\"50\"\n//           readOnly\n//           placeholder=\"Your transcribed text will appear here...\"\n//           style={{ width: '100%', marginBottom: '20px' }}\n//         />\n//         <textarea\n//           value={messages}\n//           rows=\"4\"\n//           cols=\"50\"\n//           readOnly\n//           placeholder=\"AI response will appear here...\"\n//           style={{ width: '100%' }}\n//         />\n//       </div>\n//     </div>\n//   );\n// }\n\n// export default App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["React","useState","useEffect","axios","SpeechRecognition","useSpeechRecognition","jsxDEV","_jsxDEV","App","_s","messages","setMessages","loading","setLoading","transcript","listening","resetTranscript","browserSupportsSpeechRecognition","children","fileName","_jsxFileName","lineNumber","columnNumber","handleStartListening","startListening","continuous","handleStopListening","stopListening","trim","fetchResponse","response","post","input","headers","aiMessage","data","message","prevMessages","question","answer","error","console","handleResetResponses","style","padding","maxWidth","margin","marginBottom","onClick","fontSize","marginRight","disabled","value","rows","cols","readOnly","placeholder","width","marginTop","map","msg","index","join","height","_c","$RefreshReg$"],"sources":["D:/OpenAIVoice/openvoice/src/App.js"],"sourcesContent":["import React, { useState, useEffect } from 'react';\nimport axios from 'axios';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\nfunction App() {\n  const [messages, setMessages] = useState([]); // State to store the list of Q&A pairs\n  const [loading, setLoading] = useState(false); // Loading state for API call\n  const { transcript, listening, resetTranscript } = useSpeechRecognition(); // Speech recognition hooks\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    return <div>Your browser does not support speech recognition. Please use a modern browser.</div>;\n  }\n\n  // Function to start listening to speech\n  const handleStartListening = () => {\n    if (!listening) {\n      SpeechRecognition.startListening({ continuous: true }); // Start continuous listening\n    }\n  };\n\n  // Function to stop listening to speech\n  const handleStopListening = () => {\n    if (listening) {\n      SpeechRecognition.stopListening(); // Stop listening when the button is clicked\n    }\n  };\n\n  // useEffect to call the API when listening stops\n  useEffect(() => {\n    if (!listening && transcript.trim()) {\n      const fetchResponse = async () => {\n        setLoading(true); // Start loading\n\n        try {\n          const response = await axios.post(\n            'http://localhost:4000/api/v1/search/QueryAnything', // API endpoint\n            {\n              input: transcript, // Send the transcribed message as input\n            },\n            {\n              headers: {\n                'Content-Type': 'application/json', // Set headers\n              },\n            }\n          );\n\n          // Extract the response message from the API\n          const aiMessage = response.data.message;\n\n          // Update messages state with the new Q&A\n          setMessages((prevMessages) => [\n            ...prevMessages,\n            {\n              question: transcript, // Save the transcript as the question\n              answer: aiMessage,    // Save the AI response as the answer\n            },\n          ]);\n        } catch (error) {\n          console.error('Error fetching response from API:', error); // Handle error\n          setMessages((prevMessages) => [\n            ...prevMessages,\n            {\n              question: transcript, // Save the transcript even on error\n              answer: 'Error fetching response. Please try again.', // Display error message\n            },\n          ]);\n        }\n\n        setLoading(false); // End loading\n      };\n\n      fetchResponse();\n    }\n  }, [listening, transcript]); // Dependency array to watch for changes in 'listening' and 'transcript'\n\n  // Function to reset the response text area\n  const handleResetResponses = () => {\n    setMessages([]); // Clear all Q&A pairs\n  };\n\n  return (\n    <div style={{ padding: '20px', maxWidth: '600px', margin: 'auto' }}>\n      <h1>Chat AI : Your Personal Voice Assistance</h1>\n      <div style={{ marginBottom: '20px' }}>\n        <button\n          onClick={handleStartListening}\n          style={{ padding: '10px', fontSize: '16px', marginRight: '10px' }}\n          disabled={listening} // Disable if already listening\n        >\n          Start Listening\n        </button>\n        <button\n          onClick={handleStopListening}\n          style={{ padding: '10px', fontSize: '16px', marginRight: '10px' }}\n          disabled={!listening} // Disable if not listening\n        >\n          Stop Listening\n        </button>\n        <button\n          onClick={handleResetResponses}\n          style={{ padding: '10px', fontSize: '16px' }}\n        >\n          Reset Responses\n        </button>\n        {listening && <p>Listening... Please speak now.</p>}\n      </div>\n      <div style={{ marginBottom: '20px' }}>\n        <textarea\n          value={transcript}\n          rows=\"4\"\n          cols=\"50\"\n          readOnly\n          placeholder=\"Your transcribed text will appear here...\"\n          style={{ width: '100%', marginBottom: '10px' }}\n        />\n      </div>\n      {loading ? <p>Loading response...</p> : (\n        <div style={{ marginTop: '20px' }}>\n          <textarea\n            value={messages.map((msg, index) => `Question ${index + 1}:\\n${msg.question}\\nAnswer:\\n${msg.answer}\\n\\n`).join('')}\n            rows=\"10\"\n            cols=\"50\"\n            readOnly\n            placeholder=\"AI responses will appear here...\"\n            style={{ width: '100%', height: '200px' }}\n          />\n        </div>\n      )}\n    </div>\n  );\n}\n\nexport default App;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n// import React, { useState } from 'react';\n// import axios from 'axios';\n// import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\n// function App() {\n//   const [messages, setMessages] = useState(''); // State to store the API response\n//   const [loading, setLoading] = useState(false); // Loading state for API call\n//   const { transcript, listening, resetTranscript } = useSpeechRecognition(); // Speech recognition hooks\n\n//   if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n//     return <div>Your browser does not support speech recognition. Please use a modern browser.</div>;\n//   }\n\n//   // Handle microphone click event\n//   const handleMicClick = () => {\n//     if (listening) {\n//       SpeechRecognition.stopListening(); // Stop listening when button is clicked again\n//       handleSendMessage(transcript); // Send the message to OpenAI API\n//       resetTranscript(); // Reset transcript after sending\n//     } else {\n//       SpeechRecognition.startListening(); // Start listening when button is clicked\n//     }\n//   };\n\n//   // Function to send the transcribed message to the API\n//   const handleSendMessage = async (message) => {\n//     if (!message.trim()) {\n//       alert(\"Please say something before sending.\"); // Alert if the message is empty\n//       return;\n//     }\n\n//     setLoading(true); // Start loading\n\n//     try {\n//       const response = await axios.post(\n//         'http://localhost:4000/api/v1/search/QueryAnything', // API endpoint\n//         {\n//           input: message, // Send the transcribed message as input\n//         },\n//         {\n//           headers: {\n//             'Content-Type': 'application/json', // Set headers\n//           },\n//         }\n//       );\n\n//       // Extract the response message from the API\n//       const aiMessage = response.data.message;\n//       setMessages(aiMessage); // Update messages state with API response\n//     } catch (error) {\n//       console.error('Error fetching response from API:', error); // Handle error\n//       setMessages('Error fetching response. Please try again.'); // Display error message\n//     }\n\n//     setLoading(false); // End loading\n//   };\n\n//   return (\n//     <div style={{ padding: '20px', maxWidth: '600px', margin: 'auto' }}>\n//       <h1>Chat with AI using Voice</h1>\n//       <div style={{ marginBottom: '20px' }}>\n//         <button onClick={handleMicClick} style={{ padding: '10px', fontSize: '16px' }}>\n//           {listening ? 'Stop Listening' : 'Start Listening'}\n//         </button>\n//         {listening && <p>Listening... Please speak now.</p>}\n//       </div>\n//       {loading && <p>Loading response...</p>}\n//       <div style={{ marginTop: '20px' }}>\n//         <textarea\n//           value={transcript}\n//           rows=\"4\"\n//           cols=\"50\"\n//           readOnly\n//           placeholder=\"Your transcribed text will appear here...\"\n//           style={{ width: '100%', marginBottom: '20px' }}\n//         />\n//         <textarea\n//           value={messages}\n//           rows=\"4\"\n//           cols=\"50\"\n//           readOnly\n//           placeholder=\"AI response will appear here...\"\n//           style={{ width: '100%' }}\n//         />\n//       </div>\n//     </div>\n//   );\n// }\n\n// export default App;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAClD,OAAOC,KAAK,MAAM,OAAO;AACzB,OAAOC,iBAAiB,IAAIC,oBAAoB,QAAQ,0BAA0B;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEnF,SAASC,GAAGA,CAAA,EAAG;EAAAC,EAAA;EACb,MAAM,CAACC,QAAQ,EAAEC,WAAW,CAAC,GAAGV,QAAQ,CAAC,EAAE,CAAC,CAAC,CAAC;EAC9C,MAAM,CAACW,OAAO,EAAEC,UAAU,CAAC,GAAGZ,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC;EAC/C,MAAM;IAAEa,UAAU;IAAEC,SAAS;IAAEC;EAAgB,CAAC,GAAGX,oBAAoB,CAAC,CAAC,CAAC,CAAC;;EAE3E,IAAI,CAACD,iBAAiB,CAACa,gCAAgC,CAAC,CAAC,EAAE;IACzD,oBAAOV,OAAA;MAAAW,QAAA,EAAK;IAA8E;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CAAC;EAClG;;EAEA;EACA,MAAMC,oBAAoB,GAAGA,CAAA,KAAM;IACjC,IAAI,CAACR,SAAS,EAAE;MACdX,iBAAiB,CAACoB,cAAc,CAAC;QAAEC,UAAU,EAAE;MAAK,CAAC,CAAC,CAAC,CAAC;IAC1D;EACF,CAAC;;EAED;EACA,MAAMC,mBAAmB,GAAGA,CAAA,KAAM;IAChC,IAAIX,SAAS,EAAE;MACbX,iBAAiB,CAACuB,aAAa,CAAC,CAAC,CAAC,CAAC;IACrC;EACF,CAAC;;EAED;EACAzB,SAAS,CAAC,MAAM;IACd,IAAI,CAACa,SAAS,IAAID,UAAU,CAACc,IAAI,CAAC,CAAC,EAAE;MACnC,MAAMC,aAAa,GAAG,MAAAA,CAAA,KAAY;QAChChB,UAAU,CAAC,IAAI,CAAC,CAAC,CAAC;;QAElB,IAAI;UACF,MAAMiB,QAAQ,GAAG,MAAM3B,KAAK,CAAC4B,IAAI,CAC/B,mDAAmD;UAAE;UACrD;YACEC,KAAK,EAAElB,UAAU,CAAE;UACrB,CAAC,EACD;YACEmB,OAAO,EAAE;cACP,cAAc,EAAE,kBAAkB,CAAE;YACtC;UACF,CACF,CAAC;;UAED;UACA,MAAMC,SAAS,GAAGJ,QAAQ,CAACK,IAAI,CAACC,OAAO;;UAEvC;UACAzB,WAAW,CAAE0B,YAAY,IAAK,CAC5B,GAAGA,YAAY,EACf;YACEC,QAAQ,EAAExB,UAAU;YAAE;YACtByB,MAAM,EAAEL,SAAS,CAAK;UACxB,CAAC,CACF,CAAC;QACJ,CAAC,CAAC,OAAOM,KAAK,EAAE;UACdC,OAAO,CAACD,KAAK,CAAC,mCAAmC,EAAEA,KAAK,CAAC,CAAC,CAAC;UAC3D7B,WAAW,CAAE0B,YAAY,IAAK,CAC5B,GAAGA,YAAY,EACf;YACEC,QAAQ,EAAExB,UAAU;YAAE;YACtByB,MAAM,EAAE,4CAA4C,CAAE;UACxD,CAAC,CACF,CAAC;QACJ;QAEA1B,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC;MACrB,CAAC;MAEDgB,aAAa,CAAC,CAAC;IACjB;EACF,CAAC,EAAE,CAACd,SAAS,EAAED,UAAU,CAAC,CAAC,CAAC,CAAC;;EAE7B;EACA,MAAM4B,oBAAoB,GAAGA,CAAA,KAAM;IACjC/B,WAAW,CAAC,EAAE,CAAC,CAAC,CAAC;EACnB,CAAC;EAED,oBACEJ,OAAA;IAAKoC,KAAK,EAAE;MAAEC,OAAO,EAAE,MAAM;MAAEC,QAAQ,EAAE,OAAO;MAAEC,MAAM,EAAE;IAAO,CAAE;IAAA5B,QAAA,gBACjEX,OAAA;MAAAW,QAAA,EAAI;IAAwC;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eACjDf,OAAA;MAAKoC,KAAK,EAAE;QAAEI,YAAY,EAAE;MAAO,CAAE;MAAA7B,QAAA,gBACnCX,OAAA;QACEyC,OAAO,EAAEzB,oBAAqB;QAC9BoB,KAAK,EAAE;UAAEC,OAAO,EAAE,MAAM;UAAEK,QAAQ,EAAE,MAAM;UAAEC,WAAW,EAAE;QAAO,CAAE;QAClEC,QAAQ,EAAEpC,SAAU,CAAC;QAAA;QAAAG,QAAA,EACtB;MAED;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAQ,CAAC,eACTf,OAAA;QACEyC,OAAO,EAAEtB,mBAAoB;QAC7BiB,KAAK,EAAE;UAAEC,OAAO,EAAE,MAAM;UAAEK,QAAQ,EAAE,MAAM;UAAEC,WAAW,EAAE;QAAO,CAAE;QAClEC,QAAQ,EAAE,CAACpC,SAAU,CAAC;QAAA;QAAAG,QAAA,EACvB;MAED;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAQ,CAAC,eACTf,OAAA;QACEyC,OAAO,EAAEN,oBAAqB;QAC9BC,KAAK,EAAE;UAAEC,OAAO,EAAE,MAAM;UAAEK,QAAQ,EAAE;QAAO,CAAE;QAAA/B,QAAA,EAC9C;MAED;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAQ,CAAC,EACRP,SAAS,iBAAIR,OAAA;QAAAW,QAAA,EAAG;MAA8B;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAChD,CAAC,eACNf,OAAA;MAAKoC,KAAK,EAAE;QAAEI,YAAY,EAAE;MAAO,CAAE;MAAA7B,QAAA,eACnCX,OAAA;QACE6C,KAAK,EAAEtC,UAAW;QAClBuC,IAAI,EAAC,GAAG;QACRC,IAAI,EAAC,IAAI;QACTC,QAAQ;QACRC,WAAW,EAAC,2CAA2C;QACvDb,KAAK,EAAE;UAAEc,KAAK,EAAE,MAAM;UAAEV,YAAY,EAAE;QAAO;MAAE;QAAA5B,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAChD;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACC,CAAC,EACLV,OAAO,gBAAGL,OAAA;MAAAW,QAAA,EAAG;IAAmB;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,gBACnCf,OAAA;MAAKoC,KAAK,EAAE;QAAEe,SAAS,EAAE;MAAO,CAAE;MAAAxC,QAAA,eAChCX,OAAA;QACE6C,KAAK,EAAE1C,QAAQ,CAACiD,GAAG,CAAC,CAACC,GAAG,EAAEC,KAAK,KAAK,YAAYA,KAAK,GAAG,CAAC,MAAMD,GAAG,CAACtB,QAAQ,cAAcsB,GAAG,CAACrB,MAAM,MAAM,CAAC,CAACuB,IAAI,CAAC,EAAE,CAAE;QACpHT,IAAI,EAAC,IAAI;QACTC,IAAI,EAAC,IAAI;QACTC,QAAQ;QACRC,WAAW,EAAC,kCAAkC;QAC9Cb,KAAK,EAAE;UAAEc,KAAK,EAAE,MAAM;UAAEM,MAAM,EAAE;QAAQ;MAAE;QAAA5C,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAC3C;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACC,CACN;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACE,CAAC;AAEV;AAACb,EAAA,CA9HQD,GAAG;EAAA,QAGyCH,oBAAoB;AAAA;AAAA2D,EAAA,GAHhExD,GAAG;AAgIZ,eAAeA,GAAG;;AAwBlB;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAAA,IAAAwD,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}