{"ast":null,"code":"var _jsxFileName = \"D:\\\\OpenAIVoice\\\\openvoice\\\\src\\\\App.js\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect } from 'react';\nimport axios from 'axios';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction App() {\n  _s();\n  const [messages, setMessages] = useState(''); // State to store the API response\n  const [loading, setLoading] = useState(false); // Loading state for API call\n  const {\n    transcript,\n    listening,\n    resetTranscript\n  } = useSpeechRecognition(); // Speech recognition hooks\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    return /*#__PURE__*/_jsxDEV(\"div\", {\n      children: \"Your browser does not support speech recognition. Please use a modern browser.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 11,\n      columnNumber: 12\n    }, this);\n  }\n\n  // Function to start listening to speech\n  const handleStartListening = () => {\n    if (!listening) {\n      resetTranscript(); // Reset transcript when starting a new listening session\n      SpeechRecognition.startListening({\n        continuous: true\n      }); // Start continuous listening\n    }\n  };\n\n  // Function to stop listening to speech\n  const handleStopListening = () => {\n    if (listening) {\n      SpeechRecognition.stopListening(); // Stop listening when the button is clicked\n    }\n  };\n\n  // useEffect to call the API when listening stops\n  useEffect(() => {\n    if (!listening && transcript.trim()) {\n      // Only call API when listening stops and transcript is not empty\n      const fetchResponse = async () => {\n        setLoading(true); // Start loading\n\n        try {\n          const response = await axios.post('http://localhost:4000/api/v1/search/QueryAnything',\n          // API endpoint\n          {\n            input: transcript // Send the transcribed message as input\n          }, {\n            headers: {\n              'Content-Type': 'application/json' // Set headers\n            }\n          });\n\n          // Extract the response message from the API\n          const aiMessage = response.data.message;\n          setMessages(prevMessages => prevMessages + \"\\n\" + aiMessage); // Append new messages\n        } catch (error) {\n          console.error('Error fetching response from API:', error); // Handle error\n          setMessages('Error fetching response. Please try again.'); // Display error message\n        }\n        setLoading(false); // End loading\n      };\n      fetchResponse();\n    }\n  }, [listening, transcript]); // Dependency array to watch for changes in 'listening' and 'transcript'\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    style: {\n      padding: '20px',\n      maxWidth: '600px',\n      margin: 'auto'\n    },\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \"Chat AI : Your Personal Voice Assistance\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 65,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        marginBottom: '20px'\n      },\n      children: [/*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: handleStartListening,\n        style: {\n          padding: '10px',\n          fontSize: '16px',\n          marginRight: '10px'\n        },\n        disabled: listening // Disable if already listening\n        ,\n        children: \"Start Listening\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 67,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: handleStopListening,\n        style: {\n          padding: '10px',\n          fontSize: '16px'\n        },\n        disabled: !listening // Disable if not listening\n        ,\n        children: \"Stop Listening\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 74,\n        columnNumber: 9\n      }, this), listening && /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"Listening... Please speak now.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 81,\n        columnNumber: 23\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 66,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        marginBottom: '20px'\n      },\n      children: /*#__PURE__*/_jsxDEV(\"textarea\", {\n        value: transcript,\n        rows: \"4\",\n        cols: \"50\",\n        readOnly: true,\n        placeholder: \"Your transcribed text will appear here...\",\n        style: {\n          width: '100%',\n          marginBottom: '10px'\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 84,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 83,\n      columnNumber: 7\n    }, this), loading ? /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Loading response...\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 93,\n      columnNumber: 18\n    }, this) : /*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        marginTop: '20px'\n      },\n      children: /*#__PURE__*/_jsxDEV(\"textarea\", {\n        value: `Answer:${messages}`,\n        rows: \"4\",\n        cols: \"50\",\n        readOnly: true,\n        placeholder: \"AI response will appear here...\",\n        style: {\n          width: '100%'\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 95,\n        columnNumber: 11\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 94,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 64,\n    columnNumber: 5\n  }, this);\n}\n_s(App, \"BqLxfQQfAepkpqVDuiepf6Rr7dg=\", false, function () {\n  return [useSpeechRecognition];\n});\n_c = App;\nexport default App;\n\n// import React, { useState } from 'react';\n// import axios from 'axios';\n// import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\n// function App() {\n//   const [messages, setMessages] = useState(''); // State to store the API response\n//   const [loading, setLoading] = useState(false); // Loading state for API call\n//   const { transcript, listening, resetTranscript } = useSpeechRecognition(); // Speech recognition hooks\n\n//   if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n//     return <div>Your browser does not support speech recognition. Please use a modern browser.</div>;\n//   }\n\n//   // Handle microphone click event\n//   const handleMicClick = () => {\n//     if (listening) {\n//       SpeechRecognition.stopListening(); // Stop listening when button is clicked again\n//       handleSendMessage(transcript); // Send the message to OpenAI API\n//       resetTranscript(); // Reset transcript after sending\n//     } else {\n//       SpeechRecognition.startListening(); // Start listening when button is clicked\n//     }\n//   };\n\n//   // Function to send the transcribed message to the API\n//   const handleSendMessage = async (message) => {\n//     if (!message.trim()) {\n//       alert(\"Please say something before sending.\"); // Alert if the message is empty\n//       return;\n//     }\n\n//     setLoading(true); // Start loading\n\n//     try {\n//       const response = await axios.post(\n//         'http://localhost:4000/api/v1/search/QueryAnything', // API endpoint\n//         {\n//           input: message, // Send the transcribed message as input\n//         },\n//         {\n//           headers: {\n//             'Content-Type': 'application/json', // Set headers\n//           },\n//         }\n//       );\n\n//       // Extract the response message from the API\n//       const aiMessage = response.data.message;\n//       setMessages(aiMessage); // Update messages state with API response\n//     } catch (error) {\n//       console.error('Error fetching response from API:', error); // Handle error\n//       setMessages('Error fetching response. Please try again.'); // Display error message\n//     }\n\n//     setLoading(false); // End loading\n//   };\n\n//   return (\n//     <div style={{ padding: '20px', maxWidth: '600px', margin: 'auto' }}>\n//       <h1>Chat with AI using Voice</h1>\n//       <div style={{ marginBottom: '20px' }}>\n//         <button onClick={handleMicClick} style={{ padding: '10px', fontSize: '16px' }}>\n//           {listening ? 'Stop Listening' : 'Start Listening'}\n//         </button>\n//         {listening && <p>Listening... Please speak now.</p>}\n//       </div>\n//       {loading && <p>Loading response...</p>}\n//       <div style={{ marginTop: '20px' }}>\n//         <textarea\n//           value={transcript}\n//           rows=\"4\"\n//           cols=\"50\"\n//           readOnly\n//           placeholder=\"Your transcribed text will appear here...\"\n//           style={{ width: '100%', marginBottom: '20px' }}\n//         />\n//         <textarea\n//           value={messages}\n//           rows=\"4\"\n//           cols=\"50\"\n//           readOnly\n//           placeholder=\"AI response will appear here...\"\n//           style={{ width: '100%' }}\n//         />\n//       </div>\n//     </div>\n//   );\n// }\n\n// export default App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["React","useState","useEffect","axios","SpeechRecognition","useSpeechRecognition","jsxDEV","_jsxDEV","App","_s","messages","setMessages","loading","setLoading","transcript","listening","resetTranscript","browserSupportsSpeechRecognition","children","fileName","_jsxFileName","lineNumber","columnNumber","handleStartListening","startListening","continuous","handleStopListening","stopListening","trim","fetchResponse","response","post","input","headers","aiMessage","data","message","prevMessages","error","console","style","padding","maxWidth","margin","marginBottom","onClick","fontSize","marginRight","disabled","value","rows","cols","readOnly","placeholder","width","marginTop","_c","$RefreshReg$"],"sources":["D:/OpenAIVoice/openvoice/src/App.js"],"sourcesContent":["import React, { useState, useEffect } from 'react';\nimport axios from 'axios';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\nfunction App() {\n  const [messages, setMessages] = useState(''); // State to store the API response\n  const [loading, setLoading] = useState(false); // Loading state for API call\n  const { transcript, listening, resetTranscript } = useSpeechRecognition(); // Speech recognition hooks\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    return <div>Your browser does not support speech recognition. Please use a modern browser.</div>;\n  }\n\n  // Function to start listening to speech\n  const handleStartListening = () => {\n    if (!listening) {\n      resetTranscript(); // Reset transcript when starting a new listening session\n      SpeechRecognition.startListening({ continuous: true }); // Start continuous listening\n    }\n  };\n\n  // Function to stop listening to speech\n  const handleStopListening = () => {\n    if (listening) {\n      SpeechRecognition.stopListening(); // Stop listening when the button is clicked\n    }\n  };\n\n  // useEffect to call the API when listening stops\n  useEffect(() => {\n    if (!listening && transcript.trim()) { // Only call API when listening stops and transcript is not empty\n      const fetchResponse = async () => {\n        setLoading(true); // Start loading\n\n        try {\n          const response = await axios.post(\n            'http://localhost:4000/api/v1/search/QueryAnything', // API endpoint\n            {\n              input: transcript, // Send the transcribed message as input\n            },\n            {\n              headers: {\n                'Content-Type': 'application/json', // Set headers\n              },\n            }\n          );\n\n          // Extract the response message from the API\n          const aiMessage = response.data.message;\n          setMessages((prevMessages) => prevMessages + \"\\n\" + aiMessage); // Append new messages\n        } catch (error) {\n          console.error('Error fetching response from API:', error); // Handle error\n          setMessages('Error fetching response. Please try again.'); // Display error message\n        }\n\n        setLoading(false); // End loading\n      };\n\n      fetchResponse();\n    }\n  }, [listening, transcript]); // Dependency array to watch for changes in 'listening' and 'transcript'\n\n  return (\n    <div style={{ padding: '20px', maxWidth: '600px', margin: 'auto' }}>\n      <h1>Chat AI : Your Personal Voice Assistance</h1>\n      <div style={{ marginBottom: '20px' }}>\n        <button\n          onClick={handleStartListening}\n          style={{ padding: '10px', fontSize: '16px', marginRight: '10px' }}\n          disabled={listening} // Disable if already listening\n        >\n          Start Listening\n        </button>\n        <button\n          onClick={handleStopListening}\n          style={{ padding: '10px', fontSize: '16px' }}\n          disabled={!listening} // Disable if not listening\n        >\n          Stop Listening\n        </button>\n        {listening && <p>Listening... Please speak now.</p>}\n      </div>\n      <div style={{ marginBottom: '20px' }}>\n        <textarea\n          value={transcript}\n          rows=\"4\"\n          cols=\"50\"\n          readOnly\n          placeholder=\"Your transcribed text will appear here...\"\n          style={{ width: '100%', marginBottom: '10px' }}\n        />\n      </div>\n      {loading ? <p>Loading response...</p> : (\n        <div style={{ marginTop: '20px' }}>\n          <textarea\n            value={`Answer:${messages}`}\n            rows=\"4\"\n            cols=\"50\"\n            readOnly\n            placeholder=\"AI response will appear here...\"\n            style={{ width: '100%' }}\n          />\n        </div>\n      )}\n    </div>\n  );\n}\n\nexport default App;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n// import React, { useState } from 'react';\n// import axios from 'axios';\n// import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\n// function App() {\n//   const [messages, setMessages] = useState(''); // State to store the API response\n//   const [loading, setLoading] = useState(false); // Loading state for API call\n//   const { transcript, listening, resetTranscript } = useSpeechRecognition(); // Speech recognition hooks\n\n//   if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n//     return <div>Your browser does not support speech recognition. Please use a modern browser.</div>;\n//   }\n\n//   // Handle microphone click event\n//   const handleMicClick = () => {\n//     if (listening) {\n//       SpeechRecognition.stopListening(); // Stop listening when button is clicked again\n//       handleSendMessage(transcript); // Send the message to OpenAI API\n//       resetTranscript(); // Reset transcript after sending\n//     } else {\n//       SpeechRecognition.startListening(); // Start listening when button is clicked\n//     }\n//   };\n\n//   // Function to send the transcribed message to the API\n//   const handleSendMessage = async (message) => {\n//     if (!message.trim()) {\n//       alert(\"Please say something before sending.\"); // Alert if the message is empty\n//       return;\n//     }\n\n//     setLoading(true); // Start loading\n\n//     try {\n//       const response = await axios.post(\n//         'http://localhost:4000/api/v1/search/QueryAnything', // API endpoint\n//         {\n//           input: message, // Send the transcribed message as input\n//         },\n//         {\n//           headers: {\n//             'Content-Type': 'application/json', // Set headers\n//           },\n//         }\n//       );\n\n//       // Extract the response message from the API\n//       const aiMessage = response.data.message;\n//       setMessages(aiMessage); // Update messages state with API response\n//     } catch (error) {\n//       console.error('Error fetching response from API:', error); // Handle error\n//       setMessages('Error fetching response. Please try again.'); // Display error message\n//     }\n\n//     setLoading(false); // End loading\n//   };\n\n//   return (\n//     <div style={{ padding: '20px', maxWidth: '600px', margin: 'auto' }}>\n//       <h1>Chat with AI using Voice</h1>\n//       <div style={{ marginBottom: '20px' }}>\n//         <button onClick={handleMicClick} style={{ padding: '10px', fontSize: '16px' }}>\n//           {listening ? 'Stop Listening' : 'Start Listening'}\n//         </button>\n//         {listening && <p>Listening... Please speak now.</p>}\n//       </div>\n//       {loading && <p>Loading response...</p>}\n//       <div style={{ marginTop: '20px' }}>\n//         <textarea\n//           value={transcript}\n//           rows=\"4\"\n//           cols=\"50\"\n//           readOnly\n//           placeholder=\"Your transcribed text will appear here...\"\n//           style={{ width: '100%', marginBottom: '20px' }}\n//         />\n//         <textarea\n//           value={messages}\n//           rows=\"4\"\n//           cols=\"50\"\n//           readOnly\n//           placeholder=\"AI response will appear here...\"\n//           style={{ width: '100%' }}\n//         />\n//       </div>\n//     </div>\n//   );\n// }\n\n// export default App;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAClD,OAAOC,KAAK,MAAM,OAAO;AACzB,OAAOC,iBAAiB,IAAIC,oBAAoB,QAAQ,0BAA0B;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEnF,SAASC,GAAGA,CAAA,EAAG;EAAAC,EAAA;EACb,MAAM,CAACC,QAAQ,EAAEC,WAAW,CAAC,GAAGV,QAAQ,CAAC,EAAE,CAAC,CAAC,CAAC;EAC9C,MAAM,CAACW,OAAO,EAAEC,UAAU,CAAC,GAAGZ,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC;EAC/C,MAAM;IAAEa,UAAU;IAAEC,SAAS;IAAEC;EAAgB,CAAC,GAAGX,oBAAoB,CAAC,CAAC,CAAC,CAAC;;EAE3E,IAAI,CAACD,iBAAiB,CAACa,gCAAgC,CAAC,CAAC,EAAE;IACzD,oBAAOV,OAAA;MAAAW,QAAA,EAAK;IAA8E;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CAAC;EAClG;;EAEA;EACA,MAAMC,oBAAoB,GAAGA,CAAA,KAAM;IACjC,IAAI,CAACR,SAAS,EAAE;MACdC,eAAe,CAAC,CAAC,CAAC,CAAC;MACnBZ,iBAAiB,CAACoB,cAAc,CAAC;QAAEC,UAAU,EAAE;MAAK,CAAC,CAAC,CAAC,CAAC;IAC1D;EACF,CAAC;;EAED;EACA,MAAMC,mBAAmB,GAAGA,CAAA,KAAM;IAChC,IAAIX,SAAS,EAAE;MACbX,iBAAiB,CAACuB,aAAa,CAAC,CAAC,CAAC,CAAC;IACrC;EACF,CAAC;;EAED;EACAzB,SAAS,CAAC,MAAM;IACd,IAAI,CAACa,SAAS,IAAID,UAAU,CAACc,IAAI,CAAC,CAAC,EAAE;MAAE;MACrC,MAAMC,aAAa,GAAG,MAAAA,CAAA,KAAY;QAChChB,UAAU,CAAC,IAAI,CAAC,CAAC,CAAC;;QAElB,IAAI;UACF,MAAMiB,QAAQ,GAAG,MAAM3B,KAAK,CAAC4B,IAAI,CAC/B,mDAAmD;UAAE;UACrD;YACEC,KAAK,EAAElB,UAAU,CAAE;UACrB,CAAC,EACD;YACEmB,OAAO,EAAE;cACP,cAAc,EAAE,kBAAkB,CAAE;YACtC;UACF,CACF,CAAC;;UAED;UACA,MAAMC,SAAS,GAAGJ,QAAQ,CAACK,IAAI,CAACC,OAAO;UACvCzB,WAAW,CAAE0B,YAAY,IAAKA,YAAY,GAAG,IAAI,GAAGH,SAAS,CAAC,CAAC,CAAC;QAClE,CAAC,CAAC,OAAOI,KAAK,EAAE;UACdC,OAAO,CAACD,KAAK,CAAC,mCAAmC,EAAEA,KAAK,CAAC,CAAC,CAAC;UAC3D3B,WAAW,CAAC,4CAA4C,CAAC,CAAC,CAAC;QAC7D;QAEAE,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC;MACrB,CAAC;MAEDgB,aAAa,CAAC,CAAC;IACjB;EACF,CAAC,EAAE,CAACd,SAAS,EAAED,UAAU,CAAC,CAAC,CAAC,CAAC;;EAE7B,oBACEP,OAAA;IAAKiC,KAAK,EAAE;MAAEC,OAAO,EAAE,MAAM;MAAEC,QAAQ,EAAE,OAAO;MAAEC,MAAM,EAAE;IAAO,CAAE;IAAAzB,QAAA,gBACjEX,OAAA;MAAAW,QAAA,EAAI;IAAwC;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eACjDf,OAAA;MAAKiC,KAAK,EAAE;QAAEI,YAAY,EAAE;MAAO,CAAE;MAAA1B,QAAA,gBACnCX,OAAA;QACEsC,OAAO,EAAEtB,oBAAqB;QAC9BiB,KAAK,EAAE;UAAEC,OAAO,EAAE,MAAM;UAAEK,QAAQ,EAAE,MAAM;UAAEC,WAAW,EAAE;QAAO,CAAE;QAClEC,QAAQ,EAAEjC,SAAU,CAAC;QAAA;QAAAG,QAAA,EACtB;MAED;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAQ,CAAC,eACTf,OAAA;QACEsC,OAAO,EAAEnB,mBAAoB;QAC7Bc,KAAK,EAAE;UAAEC,OAAO,EAAE,MAAM;UAAEK,QAAQ,EAAE;QAAO,CAAE;QAC7CE,QAAQ,EAAE,CAACjC,SAAU,CAAC;QAAA;QAAAG,QAAA,EACvB;MAED;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAQ,CAAC,EACRP,SAAS,iBAAIR,OAAA;QAAAW,QAAA,EAAG;MAA8B;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAChD,CAAC,eACNf,OAAA;MAAKiC,KAAK,EAAE;QAAEI,YAAY,EAAE;MAAO,CAAE;MAAA1B,QAAA,eACnCX,OAAA;QACE0C,KAAK,EAAEnC,UAAW;QAClBoC,IAAI,EAAC,GAAG;QACRC,IAAI,EAAC,IAAI;QACTC,QAAQ;QACRC,WAAW,EAAC,2CAA2C;QACvDb,KAAK,EAAE;UAAEc,KAAK,EAAE,MAAM;UAAEV,YAAY,EAAE;QAAO;MAAE;QAAAzB,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAChD;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACC,CAAC,EACLV,OAAO,gBAAGL,OAAA;MAAAW,QAAA,EAAG;IAAmB;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,gBACnCf,OAAA;MAAKiC,KAAK,EAAE;QAAEe,SAAS,EAAE;MAAO,CAAE;MAAArC,QAAA,eAChCX,OAAA;QACE0C,KAAK,EAAE,UAAUvC,QAAQ,EAAG;QAC5BwC,IAAI,EAAC,GAAG;QACRC,IAAI,EAAC,IAAI;QACTC,QAAQ;QACRC,WAAW,EAAC,iCAAiC;QAC7Cb,KAAK,EAAE;UAAEc,KAAK,EAAE;QAAO;MAAE;QAAAnC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAC1B;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACC,CACN;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACE,CAAC;AAEV;AAACb,EAAA,CAtGQD,GAAG;EAAA,QAGyCH,oBAAoB;AAAA;AAAAmD,EAAA,GAHhEhD,GAAG;AAwGZ,eAAeA,GAAG;;AAyBlB;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAAA,IAAAgD,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}